{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Finding the Most Important Factors in Weather Events using Descision Trees__\n",
    "\n",
    "Uses decision trees to find the most important factors in determining the root node (variable 'root\\_node') looking at both categorical and numeric values.<br>\n",
    "To extract the image file, use the following in terminal: $dot -Tpng tree_all.dot -o tree_all.png\n",
    "\n",
    "First Section: read in and clean the data<br>\n",
    "Second Section: clean property and crop damage as well as month data<br>\n",
    "Third Section: creates the decision tree algorithm<br>\n",
    "Fourth Section: creates the decision tree visual with removed values<br>\n",
    "Fifth Section: creates the decision tree visual with values<br>\n",
    "\n",
    "Note: only the fourth _or_ fifth section should be run, as the fifth overwrites the fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import calendar\n",
    "\n",
    "# the node to be analyzed\n",
    "root_node = 'EVENT_TYPE'\n",
    "# what the depth of the leaf nodes will be\n",
    "maxdepth = 3\n",
    "# percentage of data to use\n",
    "data_percentage = 0.1 # <0.2 recomended\n",
    "# file name for the output \".dot\" file\n",
    "output_file = \"tree_all_\"+root_node+\".dot\"\n",
    "\n",
    "# preparing and cleaning data\n",
    "df = pd.read_csv(\"Data/StormEvents_details-ftp_v1.0_d2019_c20200416.csv\")\n",
    "df = pd.concat([df, pd.read_csv(\"Data/StormEvents_details-ftp_v1.0_d2018_c20200317.csv\")])\n",
    "df = pd.concat([df, pd.read_csv(\"Data/StormEvents_details-ftp_v1.0_d2017_c20200121.csv\")])\n",
    "df = pd.concat([df, pd.read_csv(\"Data/StormEvents_details-ftp_v1.0_d2016_c20190817.csv\")])\n",
    "df = pd.concat([df, pd.read_csv(\"Data/StormEvents_details-ftp_v1.0_d2015_c20191116.csv\")])\n",
    "\n",
    "# dropping columns that do not contain data or only apply to some events\n",
    "# magnitude was dropped because it's hail size for some measurements, and wind speed for others\n",
    "df = df.drop(columns = ['BEGIN_DATE_TIME','END_DATE_TIME','MAGNITUDE','MAGNITUDE_TYPE',\n",
    "                        'FLOOD_CAUSE','CATEGORY','TOR_F_SCALE','TOR_LENGTH','TOR_WIDTH',\n",
    "                        'TOR_OTHER_WFO','TOR_OTHER_CZ_STATE','TOR_OTHER_CZ_FIPS',\n",
    "                        'TOR_OTHER_CZ_NAME','EPISODE_NARRATIVE','EVENT_NARRATIVE','DATA_SOURCE'])\n",
    "    \n",
    "# remove outside the continental US - currently disabled\n",
    "#df = df.drop(df[(df.STATE == 'HAWAII') | (df.STATE == 'ALASKA') | (df.STATE == 'E PACIFIC') | (df.STATE == 'ATLANTIC NORTH') | (df.STATE == 'ATLANTIC SOUTH') | (df.STATE == 'GULF OF MEXICO') | (df.STATE == 'HAWAII WATERS') | (df.STATE == 'PUERTO RICO') | (df.STATE == 'VIRGIN ISLANDS') | (df.STATE == 'AMERICAN SAMOA')].index)\n",
    "\n",
    "# calculate event's distance covered\n",
    "df['DISTANCE'] = ((df[\"BEGIN_LAT\"]-df[\"END_LAT\"])**2 + (df[\"BEGIN_LON\"]-df[\"END_LON\"])**2)**(1/2)\n",
    "\n",
    "# calculate event mid points, and remove the start & end locations (might want to add those back in...?)\n",
    "df[\"MID_LAT\"] = (df[\"BEGIN_LAT\"]+df[\"END_LAT\"]) / 2\n",
    "df[\"MID_LON\"] = (df[\"BEGIN_LON\"]+df[\"END_LON\"]) / 2\n",
    "df = df.drop(columns=[\"BEGIN_LAT\",\"END_LAT\",\"BEGIN_LON\",\"END_LON\"])\n",
    "\n",
    "# remove any rows with missing data, then reset the index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "df = df.loc[:round(len(df)*data_percentage),:] ### SHRINKS DATA DOWN - TEMPORARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the non-numeric values (i.e. 10.00k) to numeric (10000)\n",
    "def unit_converter(df, *argv):\n",
    "    for column in argv:\n",
    "        for i in range(len(df)):\n",
    "            num = df.loc[i,column][:-1] # grab the number\n",
    "            suffix = df.loc[i,column][-1] # grab the suffix (ie K, M, etc)\n",
    "            if (suffix == 'K'): # for thousands\n",
    "                num = float(num) * 1e3\n",
    "            elif (suffix == 'M'): # for millions\n",
    "                num = float(num) * 1e6\n",
    "            elif (suffix == 'B'): # for billions\n",
    "                num = float(num) * 1e9\n",
    "            elif (suffix == 'T'): # for trillions - not sure if this is necessary, billions is though\n",
    "                num = float(num) * 1e12\n",
    "            else:\n",
    "                raise ValueError(num,suffix)\n",
    "            df.loc[i,column] = num\n",
    "    return df\n",
    "\n",
    "df = unit_converter(df,'DAMAGE_PROPERTY','DAMAGE_CROPS')\n",
    "\n",
    "# convert months to numerical representation (Jan = 1, Feb = 2, etc.)\n",
    "mo_to_num = {name: num for num, name in enumerate(calendar.month_name) if num}\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'MONTH_NAME'] = mo_to_num[df.loc[i,'MONTH_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the root from the decision 'leaves'\n",
    "X = df.drop(columns=root_node)\n",
    "y = df[root_node]\n",
    "\n",
    "# create the categorical data\n",
    "X = pd.get_dummies(X,sparse=True)\n",
    "y = pd.get_dummies(y)\n",
    "# create the decision tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=maxdepth,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tree visual w/o values\n",
    "dotstr = tree.export_graphviz(clf, feature_names=X.columns)\n",
    "\n",
    "# remove the long list of values in the visual\n",
    "dotstr = dotstr.split('\\\\nvalue')\n",
    "string = dotstr[0]\n",
    "for i in range(1,len(dotstr)):\n",
    "    section = dotstr[i].split('\"')\n",
    "    string = string + '\"' + '\"'.join(section[1:])\n",
    "with open(\"Tree Visuals/\"+output_file, \"w\") as file:\n",
    "    file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tree visual w/ values\n",
    "with open(\"Tree Visuals/\"+output_file, \"w\") as outfile:\n",
    "    tree.export_graphviz(clf, out_file=outfile, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
